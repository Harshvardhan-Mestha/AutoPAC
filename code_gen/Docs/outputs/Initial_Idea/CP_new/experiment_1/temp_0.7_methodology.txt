### Methodology for Continual Learning on Noisy Financial Data

#### Step-by-Step Methodology

1. **Data Preprocessing**:
   - **Normalization**: Ensure that all features are normalized to have a consistent scale across the dataset. This is crucial for the stability and performance of machine learning models.
   - **Handling Missing Values**: Investigate and impute missing values in the dataset using appropriate statistical methods (e.g., median imputation).
   - **Feature Engineering**: Enhance the dataset with derived features that might capture hidden patterns better, such as rolling averages of volumes and prices, which are often useful in financial datasets.

2. **Model Selection**:
   - **Evaluating Baseline Models**: Start with simpler models (e.g., linear regression, decision trees) to establish a performance baseline.
   - **Advanced Models**: Given the complexity and noise in the data, utilize more sophisticated models like Long Short-Term Memory (LSTM) networks which are capable of capturing time-series dependencies, or a Transformer-based model adjusted for time-series forecasting.

3. **Continual Learning Setup**:
   - **Data Streaming Simulation**: Since the data arrives sequentially, simulate this environment by sequentially feeding the data into the model, mimicking real-time data flow.
   - **Window-based Training**: Implement a sliding window approach where the model is continuously trained on a fixed window of the most recent data. This window moves as new data comes in, ensuring the model stays updated with the most recent trends.
   - **Noise Adaptation**: Integrate mechanisms to adapt to varying noise levels, possibly through dynamic adjustment of the model’s learning rate or by employing noise filtering techniques before feeding data into the model.

4. **Model Training**:
   - **Loss Function**: Use a robust loss function that can reduce the influence of noisy data points on the model’s learning process. Examples include Huber loss or Quantile loss.
   - **Regular Updates**: Regularly update the model’s weights based on the new data received, using online learning algorithms or incremental learning methods.
   - **Validation Strategy**: Use a rolling validation strategy where the model’s performance is continually assessed on new data that was not included in the training set.

5. **Performance Evaluation**:
   - **Metrics**: Use metrics suitable for regression tasks such as MAE (Mean Absolute Error), RMSE (Root Mean Squared Error), and also consider financial-specific metrics like directional accuracy (percentage of predictions that correctly forecast the direction of price movement).
   - **Backtesting**: Perform backtesting by simulating the trading on historical data to evaluate the practical usability of the model in trading scenarios.

6. **Risk Management**:
   - **Confidence Estimation**: Implement a method to estimate the confidence level of predictions, potentially withholding predictions that fall below a certain confidence threshold to minimize risk.
   - **Anomaly Detection**: Incorporate anomaly detection to identify sudden, unexpected changes in the data which could indicate model drift or issues in the data stream.

7. **Model Adaptation and Optimization**:
   - **Hyperparameter Tuning**: Continuously monitor and adjust the model’s hyperparameters to optimize performance as more data is gathered.
   - **Feedback Loop**: Establish a feedback mechanism where model predictions are compared with actual outcomes to identify areas of improvement.

#### Detailed Pseudocode

```plaintext
Algorithm: Continual Learning for Financial Time-Series Forecasting

Input: Stream of financial data records
Output: Predictions for future values, model updates

Procedure ContinualLearning(data_stream):
    Initialize model with initial parameters
    Initialize data_window with the first segment of data_stream
    
    while more data in data_stream:
        new_data = get_next_data(data_stream)
        preprocess(new_data) including normalization and handling missing values
        
        if detect_noise(new_data):
            adjust_model_for_noise(new_data)
        
        data_window.update(new_data)
        train_model_on_window(data_window)
        
        if time_to_validate():
            validation_data = get_validation_data(data_window)
            evaluate_model(validation_data)
        
        prediction = model.predict(new_data)
        if is_confident(prediction):
            output(prediction)
        else:
            handle_low_confidence(prediction)
        
        update_model_incrementally(new_data)
        possibly_retrain_model_if_necessary()

        if detect_anomaly(data_window):
            handle_anomaly_in_data()
        
        adjust_hyperparameters_based_on_performance()
    
    return model
```

This pseudocode outlines a robust approach to handling streaming financial data for prediction using continual learning techniques. The focus is on adapting to new data, managing noise, and ensuring the model remains relevant over time.