I will break down each question, think through it critically, and then provide a refined methodology along with pseudocode based on the analysis.

1) Was the proposed methodology sufficiently explained?
The proposed methodology covered the key aspects like introducing the quantitative approach, establishing connection to the research problem, discussing instruments/data, analysis approach, background information, sampling, and limitations. However, some components could be explained in more detail for better clarity.

2) Were the standard or modified methods used? If modified, were the changes explained effectively?
The methodology primarily utilizes standard machine learning methods for tabular data like neural networks, gradient boosted trees, and baseline algorithms. No major modifications were proposed to the core algorithms themselves. However, the unique time-series nature of the dataset warrants additional preprocessing and handling compared to static tabular data.

3) Did the author indicate the limitations and the problems that arose while using the chosen methods?
Yes, a few key limitations were mentioned, such as the dataset may not represent all domains, compute constraints limiting the scope of the study, the metafeatures possibly not capturing all relevant characteristics, and complexities arising from temporal dependencies in time-series data.

4) Is the proposed methods appropriate for the given idea?
The proposed methods are largely appropriate for the given high-level idea of studying neural network and gradient boosted tree performance on a tabular stock market classification task. However, some additions are required to effectively handle the time-series aspect.

5) Was the methodology from the literature review adapted to the high level idea? 
The methodology draws inspiration from the large-scale empirical study in the literature review paper. However, it requires adaptations to incorporate the unique time-series characteristics present in the provided stock market dataset.

Based on this analysis, here is the refined step-by-step methodology:

1. Preprocess the dataset:
    a) Handle missing values through imputation or removal
    b) Encode categorical features if present
    c) Split data into train/val/test sets, treating each "era" as a separate sample
    d) Perform temporal/sequential splits to respect time dependencies

2. Feature Engineering:
    a) Construct additional time-series features like lags, rolling statistics, etc.
    b) Identify and handle potentially non-stationary signals 

3. Calculate metafeatures on the preprocessed dataset using PyMFE
    a) Extract statistical, information-theoretic, landmarking metafeatures
    b) Derive custom time-series metafeatures if needed

4. Train and evaluate models:
    a) Neural nets: MLPs, TabNet, TabTransformer, Temporal models (RNNs, 1D CNNs)
    b) Gradient boosted trees: XGBoost, LightGBM, CatBoost
    c) Baselines: Logistic Regression, SVMs, Decision Trees
    d) Perform rigorous hyperparameter tuning  

5. Compare performance using relevant metrics (accuracy, log-loss, time-series metrics)

6. Analyze metafeature correlations:
    a) With NN vs GBDT family performance 
    b) With individual algorithm performance
    c) Train meta-learning models to test predictive power

7. Reporting:
    a) Discuss key findings on algorithm performance 
    b) Provide insights on what metafeatures favor certain methods
    c) Address limitations and scope for future work

Pseudocode:

```python
# Preprocess data
preprocess_data(raw_data):
    handle_missing_values()
    encode_categorical_features()
    split_data_temporally(raw_data)  # Split respecting time factor
    return train, val, test

# Feature engineering 
engineer_features(data):
    data = construct_time_series_features(data)
    handle_non_stationarities(data)
    return data

# Calculate metafeatures
extract_metafeatures(data):
    stats_metafeatures = extract_statistical_metafeatures(data)
    info_metafeatures = extract_info_theoretic_metafeatures(data)
    landing_metafeatures = extract_landmarking_metafeatures(data)
    ts_metafeatures = extract_custom_time_series_metafeatures(data)
    all_metafeatures = stats_metafeatures + info_metafeatures + ... 
    return all_metafeatures

# Train and evaluate models
for model in [neural_nets, gbdts, baselines]:
    train_and_evaluate(model, train, val, test):
        tuned_model = hyperparam_tuning(model, train, val)
        test_metrics = evaluate(tuned_model, test)
        return test_metrics
        
# Metafeature analysis
metafeature_analysis(test_metrics, metafeatures):
    analyze_nn_vs_gbdt_performance(test_metrics, metafeatures)
    analyze_individual_algorithm_performance(test_metrics, metafeatures)
    meta_model = train_meta_learning_model(test_metrics, metafeatures)
    return meta_model
    
# Reporting
report_results(test_metrics, metafeatures, meta_model):
    discuss_algorithm_performance(test_metrics)
    provide_metafeature_insights(metafeatures)
    discuss_limitations()
```

This refined methodology incorporates the required adaptations to handle the time-series nature of the data, while following the core principles outlined in the literature review paper. The pseudocode outlines the key steps involved. Let me know if you need any clarification or have additional suggestions!